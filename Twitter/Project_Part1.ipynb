{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67029,"status":"ok","timestamp":1709105660662,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"tYoHFBq9FnM5","outputId":"91c444a4-6d90-4862-e31c-dfe8b01e4e92"},"outputs":[],"source":["# for installing pyspark\n","#!pip install pyspark==3.0.0\n","\n","# mount your google drive to be able to access files from your google drive !\n","from google.colab import drive # type: ignore\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"QJISg17bNQUw"},"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rkPgNYKcFyp1"},"outputs":[],"source":["import pyspark\n","\n","spark = pyspark.sql.SparkSession.builder.appName(\"Spark-Dataframe-API-Exercises\").getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"_FxVjfnPLdHF"},"source":["**1: Loading and preping the data**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QkHZLwBZF1iv"},"outputs":[],"source":["# Initialize Spark session\n","from pyspark.sql import SparkSession\n","\n","\n","\n","# Load Trump tweets data\n","tweets_df = spark.read.text(\"Trump_Tweet.txt\")\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"NDpGyDwqIPgS"},"outputs":[{"name":"stdout","output_type":"stream","text":["PythonRDD[42] at RDD at PythonRDD.scala:53\n","PythonRDD[43] at RDD at PythonRDD.scala:53\n","PythonRDD[44] at RDD at PythonRDD.scala:53\n"]}],"source":["# Load positive and negative words lists\n","import string\n","\n","#string positive_words\n","positive_words = spark.read.text(\"positive.txt\").rdd.flatMap(lambda x: x)\n","negative_words = spark.read.text(\"negative.txt\").rdd.flatMap(lambda x: x)\n","stop_words = spark.read.text(\"stopwords.txt\").rdd.flatMap(lambda x: x)\n","\n","print(positive_words)\n","print(negative_words)\n","print(stop_words)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"a4NndgSuIaXw"},"outputs":[{"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'value'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Extract tweet text and date\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m tweets_df \u001b[38;5;241m=\u001b[39m tweets_df\u001b[38;5;241m.\u001b[39mselect(split(\u001b[43mtweets_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetItem(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      4\u001b[0m                              split(tweets_df\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetItem(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pyspark\\sql\\dataframe.py:3123\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3090\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[0;32m   3091\u001b[0m \n\u001b[0;32m   3092\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3120\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[0;32m   3121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m-> 3123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   3124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[0;32m   3125\u001b[0m     )\n\u001b[0;32m   3126\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[0;32m   3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n","\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'value'"]}],"source":["from pyspark.sql.functions import split\n","# Extract tweet text and date\n","tweets_df = tweets_df.select(split(tweets_df.value, \";\").getItem(0).alias(\"tweet\"),\n","                             split(tweets_df.value, \";\").getItem(1).alias(\"date\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHE5CM8iIrIj"},"outputs":[],"source":["from pyspark.sql.functions import udf\n","from pyspark.sql.types import StringType\n","\n","# Defining a function to remove links from tweets\n","def remove_links(tweet):\n","    import re\n","    url_pattern = r'https?://\\S+|www\\.\\S+'\n","    return re.sub(url_pattern, '', tweet)\n","\n","# Defining the UDF for removing links\n","remove_links_udf = udf(remove_links, StringType())\n","\n","# Filtering out retweets\n","tweets_df = tweets_df.filter(~tweets_df.tweet.startswith(\"RT\"))\n","\n","# Applying the UDF to remove links from tweets\n","tweets_df = tweets_df.withColumn(\"tweet\", remove_links_udf(tweets_df[\"tweet\"]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1912,"status":"ok","timestamp":1709105828562,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"BurEAT23Hsvt","outputId":"b2694d3d-46d1-4279-8cd2-8f246d731b0f"},"outputs":[],"source":["tweets_df.show(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1532,"status":"ok","timestamp":1709106296346,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"ZMrIV035IQuE","outputId":"6868ec29-cc8e-4385-f2c2-ebced4932c02"},"outputs":[],"source":["from pyspark.sql.functions import to_timestamp, date_format\n","\n","# Convertir la colonne \"date\" en format de date et d'heure\n","tweets_df = tweets_df.withColumn(\"date\", to_timestamp(\"date\", \"dd/MM/yyyy HH:mm:ss\"))\n","\n","# creer la colonne year_month\n","tweets_df = tweets_df.withColumn(\"year_month\", date_format(\"date\", \"yyyy-MM\"))\n","\n","tweets_df.show(5)\n"]},{"cell_type":"markdown","metadata":{"id":"9uvPvLSJLJLO"},"source":["**2 : Sentiment Analysis Over time**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rzb0s8TcPzAb"},"outputs":[],"source":["\n","from pyspark.sql.functions import split, lower\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NauXrU7LTmVx"},"outputs":[],"source":["from pyspark.sql.functions import lower, udf, explode\n","from pyspark.sql.types import ArrayType, IntegerType\n","\n","# function to count positive and negative words\n","def count_sentiment_words(tweet):\n","    words = [word for word in tweet.split() if word not in stop_words]\n","    pos_count = sum(word in positive_words for word in words)\n","    neg_count = sum(word in negative_words for word in words)\n","    return [pos_count, neg_count]\n","\n","\n","count_sentiment_udf = udf(count_sentiment_words, ArrayType(IntegerType()))\n","\n","# Counting positive and negative words in each tweet\n","tweets_df = tweets_df.withColumn(\"pos_neg_counts\", count_sentiment_udf(lower(tweets_df[\"tweet\"])))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgF4zK7lU0eq"},"outputs":[],"source":["# Exploding the pos_neg_counts array column\n","tweets_df = tweets_df.select(\"tweet\", \"date\", \"year_month\",\n","                             tweets_df.pos_neg_counts[0].alias(\"pos_count\"),\n","                             tweets_df.pos_neg_counts[1].alias(\"neg_count\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142440,"status":"ok","timestamp":1709106447500,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"b2PL_FimU5SU","outputId":"52c93cf8-167a-4adb-ceea-e79414940aef"},"outputs":[],"source":["from pyspark.sql.functions import col\n","\n","# Filtering out rows with null values in the year_month column\n","tweets_df_filtered = tweets_df.filter(col(\"year_month\").isNotNull())\n","\n","# Aggregating sentiment counts by year-month\n","sentiment_counts = tweets_df_filtered.groupBy(\"year_month\").sum(\"pos_count\", \"neg_count\").orderBy(\"year_month\")\n","\n","\n","sentiment_counts.show(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"elapsed":765,"status":"ok","timestamp":1709109344749,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"7_lecOHva_EX","outputId":"279affc8-0947-4a14-b28b-9a66e04f12a4"},"outputs":[],"source":["#i wanted to try out ploting this without converting so i needed the type\n","type(sentiment_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":151434,"status":"ok","timestamp":1709109504019,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"EC2FFlTeYyGR","outputId":"89cfe938-bf39-4aeb-aa4b-abf7d43a7fb2"},"outputs":[],"source":["# Import necessary libraries\n","import matplotlib.pyplot as plt\n","\n","# Plotting positive and negative word counts over time\n","sentiment_counts.select(\"year_month\", \"sum(pos_count)\", \"sum(neg_count)\") \\\n","    .toPandas() \\\n","    .plot(x=\"year_month\", figsize=(10, 6))\n","plt.xlabel(\"Year-Month\")\n","plt.ylabel(\"Word Count\")\n","plt.title(\"Frequency of Positive and Negative Words Over Time\")\n","plt.xticks(rotation=45)\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"6zfwI6AYd20j"},"source":["\n","\n","*   Key 1 : Throughout the period spanning from 2009 to 2020, the cumulative count of\n","negative words consistently remains lower than the cumulative count of positive words.\n","\n","\n","* Key 2 : We see a decline in positive tweets ( and\n","tweets in general) at the surrounding the begining of 2016, this could be due to either one of these reasons :\n","1. Donald Trump was not tweeting as much as before since he was preparing his presidential compaign.\n","2. Donald Trump was spreading his racist thoughts so it was interpreted as negative (as it should).  \n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"prDTzfXbBE2R"},"source":["**3 : Top Hashtags and references**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDqlEvaQ1Z42"},"outputs":[],"source":["from pyspark.sql.types import StructType, StructField, ArrayType, StringType\n","\n","#  function to extract hashtags and references while filtering out stop words\n","def extract_hashtags_and_references(tweet):\n","    words = [word for word in tweet.split() if word.lower() not in stop_words]\n","    hashtags = [word.lower() for word in words if word.startswith(\"#\")]\n","    references = [word.lower() for word in words if word.startswith(\"@\")]\n","    return hashtags, references\n","\n","#  the return type for the UDF\n","return_type = StructType([\n","    StructField(\"hashtags\", ArrayType(StringType(), True)),\n","    StructField(\"references\", ArrayType(StringType(), True))\n","])\n","\n","# Registering the UDF with the correct return type\n","extract_hashtags_and_references_udf = udf(extract_hashtags_and_references, return_type)\n","\n","# Extracting hashtags and references while filtering out stop words\n","hashtags_references_df = tweets_df.withColumn(\"hashtags_and_references\", extract_hashtags_and_references_udf(lower(tweets_df[\"tweet\"])))\n","\n","# Exploding the hashtags and references array columns\n","hashtags_df = hashtags_references_df.select(explode(\"hashtags_and_references.hashtags\").alias(\"hashtag\")).groupBy(\"hashtag\").count().orderBy(\"count\", ascending=False)\n","references_df = hashtags_references_df.select(explode(\"hashtags_and_references.references\").alias(\"reference\")).groupBy(\"reference\").count().orderBy(\"count\", ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OYjhhiCN1eLG"},"outputs":[],"source":["# Loading stop words from file\n","stop_words = spark.read.text(\"drive/MyDrive/5A IR/TBS/Spark/Donald Trump/stop-words.txt\").rdd.map(lambda row: row.value.lower()).collect()\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KwV-VE1W9tNS"},"outputs":[],"source":["from pyspark.sql.functions import lower, explode\n","from pyspark.sql.types import ArrayType, StringType\n","\n","# Defining the UDF to extract hashtags\n","def extract_hashtags(tweet):\n","    stop_words_set = set(stop_words)  # Convert stop_words to a set for faster lookup\n","    words = [word for word in tweet.split() if word.lower() not in stop_words_set]\n","    hashtags = [word.lower().strip('#[]\"\"') for word in words if word.startswith(\"#\")]\n","    return hashtags\n","\n","# Registering the UDF with the correct return type\n","return_type = ArrayType(StringType(), True)\n","extract_hashtags_udf = udf(extract_hashtags, return_type)\n","\n","# Applying the UDF to extract hashtags\n","hashtags_df = tweets_df.withColumn(\"hashtags\", explode(extract_hashtags_udf(lower(tweets_df[\"tweet\"])))).groupBy(\"hashtags\").count().orderBy(\"count\", ascending=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bm6iROvT2kJE"},"outputs":[],"source":["# Convert Spark DataFrames to Pandas DataFrames for visualization\n","hashtags_pd = hashtags_df.limit(10).toPandas()\n","#references_pd = references_df.limit(10).toPandas()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1709111365256,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"mwmYc-TW-cJJ","outputId":"25b97d4b-7948-48cd-9340-718d5ead5e73"},"outputs":[],"source":["print(hashtags_pd.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1709111502474,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"0QTnLvng-c7c","outputId":"6e6d098d-a5d0-4d49-e31b-0e02860143ca"},"outputs":[],"source":["#doing this to solve errors and see why it doen't wanna work\n","print(\"First few rows of hashtags_pd DataFrame:\")\n","print(hashtags_pd.head(10))\n","\n","print(\"\\nFirst few rows of references_pd DataFrame:\")\n","#print(references_pd.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":948,"status":"ok","timestamp":1709111505463,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"cCNittxY1sD4","outputId":"7f35b874-393a-4c00-ab9e-f56e9976b2bd"},"outputs":[],"source":["# Filter out singular numbers from the hashtags\n","hashtags_pd_filtered = hashtags_pd[~hashtags_pd['hashtags'].str.match(r'^\\d$')]\n","\n","# Plotting top hashtags\n","plt.figure(figsize=(10, 6))\n","plt.bar(hashtags_pd_filtered[\"hashtags\"], hashtags_pd_filtered[\"count\"], color=\"skyblue\")\n","plt.xlabel(\"Hashtag\")\n","plt.ylabel(\"Count\")\n","plt.title(\"Top 10 Hashtags in Trump's Tweets\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"Ik_OaODxXNs2"},"source":["\n","Key 3 : As we see the top hashtags refer to his presidential compaign in 2016."]},{"cell_type":"markdown","metadata":{"id":"2lkb10_GLkEI"},"source":["**4 : Word cloud of most used words**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"executionInfo":{"elapsed":19044,"status":"ok","timestamp":1709111563291,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"q3tlXfX6Lsn7","outputId":"bf46c7fc-8715-4a7e-e837-68c1ec0a7d37"},"outputs":[],"source":["from wordcloud import WordCloud\n","\n","# Extracting all words from tweets\n","all_words = tweets_df.select(explode(split(tweets_df.tweet, \" \")).alias(\"word\")).rdd.map(lambda x: x[0]).collect()\n","\n","# Filtering out stop words\n","all_words_filtered = [word for word in all_words if word.lower() not in stop_words]\n","\n","# Creating a word cloud\n","wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\" \".join(all_words_filtered))\n","\n","# Displaying the word cloud\n","plt.figure(figsize=(10, 6))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis('off')\n","plt.title(\"Word Cloud of Most Used Words in Trump's Tweets (Without Stop Words)\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"gwnUPZrKX0CZ"},"source":["Key 4 : We clearly notice a pattern in here relating to the presendential compaign held in 2016. So we see a lot of \"vote\"; \"great\" \"america\" \"white house\" etc.."]},{"cell_type":"markdown","metadata":{"id":"u2nedaNuMqrf"},"source":["**5: Tweet volume over time**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6219,"status":"ok","timestamp":1708529155918,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"sO2Et2bdMwIp","outputId":"306d200b-eab5-4dab-cd0c-d5752b824c5d"},"outputs":[],"source":["# Show the DataFrame to inspect the data\n","tweets_df.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CuqLdw4OVwAd"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9955,"status":"ok","timestamp":1708529168469,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"X3j62eE0NLgn","outputId":"9c965dea-ee3b-4a8b-f1f9-c86cf24490e0"},"outputs":[],"source":["# Filtering out null values in the 'year_month' column\n","tweets_df = tweets_df.filter(tweets_df[\"year_month\"].isNotNull())\n","\n","tweets_df.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1708529171085,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"6xtzl4K1Nwk9","outputId":"4cd91ab2-8991-499a-eeea-723f32664f72"},"outputs":[],"source":["tweet_volume_pd.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":1757,"status":"ok","timestamp":1708529175136,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"d_tK1TpiNbek","outputId":"2c2b493f-f987-4869-c212-97c00777a7d1"},"outputs":[],"source":["# Filtering out rows with None values in the 'year_month' column\n","tweet_volume_pd_filtered = tweet_volume_pd.dropna(subset=['year_month'])\n","\n","# Plotting tweet volume over time\n","plt.figure(figsize=(10, 6))\n","plt.plot(tweet_volume_pd_filtered[\"year_month\"], tweet_volume_pd_filtered[\"count\"], color=\"orange\")\n","plt.xlabel(\"Year-Month\")\n","plt.ylabel(\"Tweet Count\")\n","plt.title(\"Tweet Volume Over Time\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"elapsed":3171,"status":"ok","timestamp":1708529180884,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"UQ-_rI9vNbiw","outputId":"a03c573b-b6a3-4223-a99b-c493d882e869"},"outputs":[],"source":["from pyspark.sql.functions import year\n","\n","# Transforming the date column into a year column\n","tweets_df = tweets_df.withColumn(\"year\", year(\"date\"))\n","\n","# Aggregating tweet counts by year\n","tweet_volume_yearly = tweets_df.groupBy(\"year\").count().orderBy(\"year\")\n","\n","# Collecting data from tweet_volume_yearly DataFrame\n","years = [row['year'] for row in tweet_volume_yearly.collect()]\n","counts = [row['count'] for row in tweet_volume_yearly.collect()]\n","\n","# Plotting tweet volume over years\n","plt.figure(figsize=(10, 6))\n","plt.plot(years, counts, color=\"orange\")\n","plt.xlabel(\"Year\")\n","plt.ylabel(\"Tweet Count\")\n","plt.title(\"Tweet Volume Over Years\")\n","plt.xticks(rotation=45)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"fPclN6yX_lE8"},"source":["Key 5 : This confirms a hypothesis that we have made earlier. indeed surrounding the Presidential compaign Donald Trump was posting less so we have a decrease in the volume of tweets."]},{"cell_type":"markdown","metadata":{"id":"Fs3XRKwv_4HB"},"source":["**Bonus**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2531,"status":"ok","timestamp":1709115698000,"user":{"displayName":"Wissal Elkourdi","userId":"06771243041514627507"},"user_tz":-60},"id":"EiwJ2grjM4Hj","outputId":"a4561982-014d-40ca-b118-ec57091aefb5"},"outputs":[],"source":["!pip install sparknlp==3.3.1\n","\n","from sparknlp.annotator import *\n","from sparknlp.common import *\n","from sparknlp.base import *\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOIBrWc6Lb0SJLm+Jrr9wF4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
